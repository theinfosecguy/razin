# Razin - Claude Code Skill Scanner

## What this project is

Razin is a static analysis scanner for `SKILL.md`-defined agent skills. It discovers skill files in a workspace, parses them, runs detector rules against their content, and writes deterministic JSON reports (findings + summaries per skill).

## Scope boundaries

### In scope
- `SKILL.md` files: the primary scan target. Parse frontmatter + body, run all detectors.
- `.mcp.json` files: directly tied to skills via `requires: mcp` in frontmatter. Skills declare MCP dependencies; the MCP config resolves them into running servers. Scanning one without the other leaves a gap in the same trust chain.
- Presence detection of bundled scripts: flag that a skill ships executable files (`*.sh`, `*.py`, `*.js`) alongside its `SKILL.md`. This is a risk signal. Do NOT parse or analyze script contents.

### Out of scope
- Hook configs (`.claude/settings.json` hooks): these are project-level agent configuration, not skill definitions. Different scanning domain.
- `CLAUDE.md` / `AGENTS.md`: project-level agent instructions, not skill files.
- Script content analysis: skills commonly bundle `scripts/` directories with Python, bash, and JS files. The `SKILL.md` already contains the signal that scripts are being executed (caught by `EXEC_FIELDS` and field-level detectors). Scanning script contents means building a multi-language SAST tool, which is a different product.
- Executing or applying skills: static analysis only, never run skill code.

## Development

```bash
uv sync --dev                              # install deps
uv run razin scan --root . --out output/  # run scanner
uv run python -m pytest -q                 # run tests (37 tests)
uv run python -m ruff check .              # lint
uv run python -m mypy src/                 # type check
```

## Architecture

Pipeline: **discover -> parse -> detect -> score -> report**

```
cli/main.py          CLI entrypoint, argparse
config.py            YAML config loading, fingerprinting
scanner/
  discovery.py       Glob-based SKILL.md file discovery
  orchestrator.py    End-to-end scan pipeline with caching
  cache.py           SHA256+mtime cache with atomic persistence
  score.py           Score-to-severity mapping, probabilistic aggregation
parsers/
  skill_markdown.py  SKILL.md parser (YAML frontmatter + line extraction)
detectors/
  base.py            Abstract Detector base class (strategy pattern)
  rules.py           Core detectors (NET_RAW_IP, SECRET_REF, EXEC_FIELDS, etc.)
  docs/rules.py      Doc-surface detectors (MCP_REQUIRED, TOOL_INVOCATION, etc.)
reporting/
  writer.py          Per-skill findings.json + summary.json output
model/entities.py    Frozen dataclasses (Finding, Evidence, ParsedSkillDocument, etc.)
types/               Shared type aliases (Severity, Confidence, CachePayload)
constants/           All threshold values, patterns, filenames
exceptions/          Exception hierarchy (RazinError -> ConfigError, SkillParseError)
io/                  File hashing, atomic JSON read/write
utils/               Name sanitization, similarity normalization
```

## Key conventions

- Frozen dataclasses for all data models. No mutable state in core types.
- Strategy pattern for detectors: subclass `Detector`, define `rule_id` class attribute, implement `run()`.
- Atomic JSON writes via `tempfile` + `os.replace` to prevent corruption.
- Constants centralized in `src/razin/constants/`. No inline magic numbers.
- Exceptions centralized in `src/razin/exceptions/`. No ad-hoc exception classes in feature modules.
- All detectors return `list[FindingCandidate]`; the orchestrator converts to `Finding` with deterministic IDs.
- Cache invalidation uses SHA256 + mtime_ns + config fingerprint. Stale keys are evicted.
- Scoring: 0-100 scale. Thresholds: >=70 high, >=40 medium, <40 low.
- Aggregation: probabilistic OR (`1 - product(1 - p_i)`) across independent risk signals.
- Never add decorative comment separators (e.g., `# -----`, `# =====`, `# *****`). Use blank lines and clear naming to organize code sections.

## Commit and PR Guidelines

### Commit Guidelines
- Commit messages must be single-line only.
- Every commit message must start with one type prefix: `feat:`, `fix:`, `refactor:`, `docs:`, `test:`, `chore:`.
- Do not use emojis in commit messages.
- Do not add co-committer attribution generated by assistant tooling.
- Do not include sprint numbers/names in branch names.
- Prefer scope-based branch names (e.g., `feat/branding-identity-polish`).

### PR Guidelines
- Create pull requests only with `gh` CLI (`gh pr create`).
- PR titles must be sentence case: capitalize only the first character (except proper nouns/acronyms).
- Do not prefix PR titles with commit-style tags (`feat:`, `fix:`, `chore:`, etc.).
- Do not mention sprint numbers/names in PR titles or descriptions unless explicitly requested.
- PR descriptions must contain exactly two H2 sections and no additional H2 sections:
- `## Problem Statement`
- `## Testing`
- The `## Testing` section must include the executed test command(s) and the resulting output.
- Do not include a changed-files list in PR descriptions.
- Use concise, human writing.
- Do not mention Codex, Claude, or any assistant authorship in PR text.

## Known issues to address

- Service-tool token detection uses a curated service-prefix heuristic and may need tuning after larger corpus scans.
- Cache namespaces are keyed by config + rulepack fingerprints; orchestrator-only suppression logic changes still require a cache refresh to reflect new behavior.
